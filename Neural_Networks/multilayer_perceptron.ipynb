{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "The code below is borrowed from Flux Model-Zoo [example](hhttps://github.com/FluxML/model-zoo/blob/master/vision/mlp_mnist/mlp_mnist.jl). I'm adding annotation and explanation in order to better understand what is happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: onehotbatch, onecold, @epochs\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Base: @kwdef\n",
    "using CUDA\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getdata (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getdata(args, device)\n",
    "    ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"\n",
    "\n",
    "    # Loading Dataset\n",
    "    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "    xtest, ytest = MLDatasets.MNIST.testdata(Float32)\n",
    "\n",
    "    # Reshape Data in order to flatten each image into a linear array\n",
    "    xtrain = Flux.flatten(xtrain)\n",
    "    xtest = Flux.flatten(xtest)\n",
    "\n",
    "    # One-hot-encode the labels\n",
    "    ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)\n",
    "\n",
    "    # Create DataLoaders (mini-batch iterators)\n",
    "    train_loader = DataLoader((xtrain, ytrain), batchsize=args.batchsize, shuffle=true)\n",
    "    test_loader = DataLoader((xtest, ytest), batchsize=args.batchsize)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dense neural network with:\n",
    "1. Input layer: size 28x28x1\n",
    "2. Hidden layer: size 32x1 with reLU activation function\n",
    "3. Hidden layer: size 32x1 with no activation function (linear transformation)\n",
    "4. Output layer: size 10\n",
    "\n",
    "\n",
    "Questions:\n",
    "1. Why doesn't the second dense layer have an activation function?\n",
    "2. Why doesn't the output layer have an activation function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_model (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function build_model(; imgsize=(28,28,1), nclasses=10)\n",
    "    return Chain(\n",
    "        Dense(prod(imgsize), 32, relu),\n",
    "        Dense(32, nclasses))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax function outputs a vector of probabilities of n length.\n",
    "$$\\frac{e^{y_i}}{\\sum^n_{j}e^{y_j}}$$\n",
    "\n",
    "loss function is logit crossentropy\n",
    "\n",
    "$$\\frac{-\\sum^{n}{\\bf{y} * \\log{softmax(\\hat{\\bf{y}})}}}{n}$$\n",
    "\n",
    "accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_and_accuracy(data_loader, model, device)\n",
    "    acc = 0\n",
    "    ls = 0.0f0\n",
    "    num = 0\n",
    "    for (x, y) in data_loader\n",
    "        x, y = device(x), device(y)\n",
    "        ŷ = model(x)\n",
    "        ls += logitcrossentropy(model(x), y, agg=sum)\n",
    "        acc += sum(onecold(cpu(model(x))) .== onecold(cpu(y)))\n",
    "        num +=  size(x, 2)\n",
    "    end\n",
    "    return ls / num, acc / num\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguements accepted by train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kwdef mutable struct Args\n",
    "    η::Float64 = 3e-4       # learning rate\n",
    "    batchsize::Int = 256    # batch size\n",
    "    epochs::Int = 10        # number of epochs\n",
    "    use_cuda::Bool = true   # use gpu (if cuda available)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...) # collect options in a struct for convenience\n",
    "\n",
    "    if CUDA.functional() && args.use_cuda\n",
    "        @info \"Training on CUDA GPU\"\n",
    "        CUDA.allowscalar(false)\n",
    "        device = gpu\n",
    "    else\n",
    "        @info \"Training on CPU\"\n",
    "        device = cpu\n",
    "    end\n",
    "\n",
    "    # Create test and train dataloaders\n",
    "    train_loader, test_loader = getdata(args, device)\n",
    "\n",
    "    # Construct model\n",
    "    model = build_model() |> device\n",
    "    ps = Flux.params(model) # model's trainable parameters\n",
    "    \n",
    "    ## Optimizer\n",
    "    opt = ADAM(args.η)\n",
    "    \n",
    "    ## Training\n",
    "    for epoch in 1:args.epochs\n",
    "        for (x, y) in train_loader\n",
    "            x, y = device(x), device(y) # transfer data to device\n",
    "            gs = gradient(() -> logitcrossentropy(model(x), y), ps) # compute gradient\n",
    "            Flux.Optimise.update!(opt, ps, gs) # update parameters\n",
    "        end\n",
    "        \n",
    "        # Report on train and test\n",
    "        train_loss, train_acc = loss_and_accuracy(train_loader, model, device)\n",
    "        test_loss, test_acc = loss_and_accuracy(test_loader, model, device)\n",
    "        println(\"Epoch=$epoch\")\n",
    "        println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "        println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "    end\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on CPU\n",
      "└ @ Main In[20]:9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1\n",
      "  train_loss = 0.58702844, train_accuracy = 0.8582166666666666\n",
      "  test_loss = 0.5663061, test_accuracy = 0.8667\n",
      "Epoch=2\n",
      "  train_loss = 0.39506525, train_accuracy = 0.8982166666666667\n",
      "  test_loss = 0.38087246, test_accuracy = 0.9048\n",
      "Epoch=3\n",
      "  train_loss = 0.33085406, train_accuracy = 0.9101\n",
      "  test_loss = 0.3210697, test_accuracy = 0.9145\n",
      "Epoch=4\n",
      "  train_loss = 0.295957, train_accuracy = 0.9188\n",
      "  test_loss = 0.28966498, test_accuracy = 0.9211\n",
      "Epoch=5\n",
      "  train_loss = 0.2740223, train_accuracy = 0.9240666666666667\n",
      "  test_loss = 0.27111995, test_accuracy = 0.9254\n",
      "Epoch=6\n",
      "  train_loss = 0.25454944, train_accuracy = 0.9292\n",
      "  test_loss = 0.25350928, test_accuracy = 0.9301\n",
      "Epoch=7\n",
      "  train_loss = 0.24209398, train_accuracy = 0.9321666666666667\n",
      "  test_loss = 0.24446595, test_accuracy = 0.9332\n",
      "Epoch=8\n",
      "  train_loss = 0.23079434, train_accuracy = 0.9363833333333333\n",
      "  test_loss = 0.23403232, test_accuracy = 0.9335\n",
      "Epoch=9\n",
      "  train_loss = 0.22088745, train_accuracy = 0.9381\n",
      "  test_loss = 0.22510451, test_accuracy = 0.937\n",
      "Epoch=10\n",
      "  train_loss = 0.2124068, train_accuracy = 0.9401166666666667\n",
      "  test_loss = 0.21714799, test_accuracy = 0.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(784, 32, relu),                 \u001b[90m# 25_120 parameters\u001b[39m\n",
       "  Dense(32, 10),                        \u001b[90m# 330 parameters\u001b[39m\n",
       ")\u001b[90m                   # Total: 4 arrays, \u001b[39m25_450 parameters, 99.664 KiB."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[0.049993202 -0.06393898 … -0.06987077 0.04271984; -0.061495777 -0.014502867 … 0.0018826268 0.051979214; … ; 0.042647757 -0.049728796 … -0.08447711 0.07487877; 0.054329116 -0.062309947 … 0.03573599 0.047698807], Float32[0.058615033, 0.07206579, 0.10467072, 0.09704774, -0.03483924, 0.04263985, 0.14307258, -0.06871432, -0.066273786, 0.035063792  …  0.10930989, 0.088000655, 0.12883368, 0.021055035, 0.119266994, -0.057405416, 0.14141738, 0.119340084, 0.08043698, -0.06795475], Float32[-0.26071203 -0.42110112 … 0.15960893 -0.3156442; 0.46470702 0.070996575 … 0.21388298 0.26626477; … ; 0.30768564 0.26401868 … -0.45963842 0.41523233; -0.4036806 0.44423026 … 0.12616383 -0.44311807], Float32[-0.07924302, 0.08012125, -0.047721677, -0.026696526, 0.03917007, 0.087582976, 0.027365515, 0.062117185, -0.13889477, -0.04218835]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dense(784, 32, relu), Dense(32, 10))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
