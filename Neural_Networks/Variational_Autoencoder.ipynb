{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using Flux, Flux.Optimise\n",
    "using Flux: onehotbatch, onecold, flatten, @epochs, logitcrossentropy\n",
    "using Base.Iterators: partition\n",
    "using Images: channelview\n",
    "using Base: @kwdef\n",
    "using Metalhead: trainimgs, valimgs\n",
    "using Images.ImageCore\n",
    "using CUDA\n",
    "using Distributions\n",
    "using Flux.Data: DataLoader\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getdata (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getdata(args, device)\n",
    "    ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\"\n",
    "\n",
    "    # Loading Dataset\t\n",
    "    xtrain, ytrain = MLDatasets.MNIST.traindata(Float32)\n",
    "    xtest, ytest = MLDatasets.MNIST.testdata(Float32)\n",
    "\t\n",
    "    # Reshape Data in order to flatten each image into a linear array\n",
    "    xtrain = Flux.flatten(xtrain)\n",
    "    xtest = Flux.flatten(xtest)\n",
    "\n",
    "    # One-hot-encode the labels\n",
    "    ytrain, ytest = onehotbatch(ytrain, 0:9), onehotbatch(ytest, 0:9)\n",
    "\n",
    "    # Create DataLoaders (mini-batch iterators)\n",
    "    train_loader = DataLoader((xtrain, ytrain), batchsize=args.batchsize, shuffle=true)\n",
    "    test_loader = DataLoader((xtest, ytest), batchsize=args.batchsize)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "build_model (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function build_model(; imgsize=(28,28,1), nclasses=10)\n",
    "    return Chain(\n",
    " \t        Dense(prod(imgsize), 32, relu),\n",
    "            Dense(32, nclasses))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_and_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_and_accuracy(data_loader, model, device)\n",
    "    acc = 0\n",
    "    ls = 0.0f0\n",
    "    num = 0\n",
    "    for (x, y) in data_loader\n",
    "        x, y = device(x), device(y)\n",
    "        ŷ = model(x)\n",
    "        ls += logitcrossentropy(model(x), y, agg=sum)\n",
    "        acc += sum(onecold(cpu(model(x))) .== onecold(cpu(y)))\n",
    "        num +=  size(x, 2)\n",
    "    end\n",
    "    return ls / num, acc / num\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kwdef mutable struct Args\n",
    "    η::Float64 = 3e-4       # learning rate\n",
    "    batchsize::Int = 256    # batch size\n",
    "    epochs::Int = 10        # number of epochs\n",
    "    use_cuda::Bool = true   # use gpu (if cuda available)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(; kws...)\n",
    "    args = Args(; kws...) # collect options in a struct for convenience\n",
    "\n",
    "    if CUDA.functional() && args.use_cuda\n",
    "        @info \"Training on CUDA GPU\"\n",
    "        CUDA.allowscalar(false)\n",
    "        device = gpu\n",
    "    else\n",
    "        @info \"Training on CPU\"\n",
    "        device = cpu\n",
    "    end\n",
    "\n",
    "    # Create test and train dataloaders\n",
    "    train_loader, test_loader = getdata(args, device)\n",
    "\n",
    "    # Construct model\n",
    "    model = build_model() |> device\n",
    "    ps = Flux.params(model) # model's trainable parameters\n",
    "    \n",
    "    ## Optimizer\n",
    "    opt = ADAM(args.η)\n",
    "    \n",
    "    ## Training\n",
    "    for epoch in 1:args.epochs\n",
    "        for (x, y) in train_loader\n",
    "            x, y = device(x), device(y) # transfer data to device\n",
    "            gs = gradient(() -> logitcrossentropy(model(x), y), ps) # compute gradient\n",
    "            Flux.Optimise.update!(opt, ps, gs) # update parameters\n",
    "        end\n",
    "        \n",
    "        # Report on train and test\n",
    "        train_loss, train_acc = loss_and_accuracy(train_loader, model, device)\n",
    "        test_loss, test_acc = loss_and_accuracy(test_loader, model, device)\n",
    "        println(\"Epoch=$epoch\")\n",
    "        println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "        println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training on CUDA GPU\n",
      "└ @ Main In[6]:5\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: objects of type UInt8 are not callable",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type UInt8 are not callable",
      "",
      "Stacktrace:",
      " [1] Pullback",
      "   @ ./In[6]:27 [inlined]",
      " [2] (::typeof(∂(λ)))(Δ::Float32)",
      "   @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface2.jl:0",
      " [3] (::Zygote.var\"#90#91\"{Zygote.Params, typeof(∂(λ)), Zygote.Context})(Δ::Float32)",
      "   @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:348",
      " [4] gradient(f::Function, args::Zygote.Params)",
      "   @ Zygote ~/.julia/packages/Zygote/TaBlo/src/compiler/interface.jl:76",
      " [5] train(; kws::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "   @ Main ./In[6]:27",
      " [6] train()",
      "   @ Main ./In[6]:2",
      " [7] top-level scope",
      "   @ In[9]:2",
      " [8] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [9] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "### Run training \n",
    "train()\n",
    "# train(η=0.01) # can change hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
